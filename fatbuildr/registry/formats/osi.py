#!/usr/bin/env python3
#
# Copyright (C) 2021 Rackslab
#
# This file is part of Fatbuildr.
#
# Fatbuildr is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Fatbuildr is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Fatbuildr.  If not, see <https://www.gnu.org/licenses/>.

import shutil
import re

from . import Registry, RegistryArtifact
from ...errors import FatbuildrTaskExecutionError
from ...log import logr

logger = logr(__name__)


class RegistryOsi(Registry):
    """Registry for Osi format (aka. OS images)."""

    CHECKSUMS_FILE_EXT = 'SHA256SUMS'

    def __init__(self, conf, instance):
        super().__init__(conf, instance, 'osi')

    @property
    def distributions(self):
        return [item.name for item in self.path.iterdir()]

    def derivatives(self, distribution):
        self._check_distribution(distribution)
        return [
            item.name for item in self.path.joinpath(distribution).iterdir()
        ]

    def derivative_path(self, distribution, derivative):
        return self.path.joinpath(distribution, derivative)

    def publish(self, build):
        """Publish OSI images."""

        logger.info("Publishing OSI images for %s", build.artifact)

        derivative_path = self.derivative_path(
            build.distribution, build.derivative
        )
        dist_path = derivative_path.parent
        format_registry_path = self.path
        instance_registry_path = self.path.parent

        # ensure registry (ie. instance, osi, etc) directories exist
        RegistryOsi.ensure_directory(instance_registry_path)
        RegistryOsi.ensure_directory(format_registry_path)
        RegistryOsi.ensure_directory(dist_path)
        RegistryOsi.ensure_directory(derivative_path)

        def read_checksum_file(checksum_path):
            results = []
            with open(checksum_path) as fh:
                for line in fh:
                    results.append(line.strip().split(' *'))
            return results

        # Copy or merge checksum file generated by mkosi
        new_checksum_path = build.place.joinpath(
            f"{build.artifact}_{build.version.main}.{self.CHECKSUMS_FILE_EXT}"
        )

        # Check checksum file exists or raise error
        if not new_checksum_path.exists():
            raise FatbuildrTaskExecutionError(
                f"Unable to find OSI checksum file {new_checksum_path}"
            )

        derivative_checksum_path = derivative_path.joinpath(
            self.CHECKSUMS_FILE_EXT
        )
        if not derivative_checksum_path.exists():
            logger.debug(
                "Deploying new checksum file %s in registry", new_checksum_path
            )
            shutil.copyfile(new_checksum_path, derivative_checksum_path)
        else:
            new_checksums = read_checksum_file(new_checksum_path)
            existing_checksums = read_checksum_file(derivative_checksum_path)
            merged_checksums = []
            # Add checksums of new files in merged checksums list
            for new_checksum in new_checksums:
                if new_checksum[1] not in [
                    existing_checksum[1]
                    for existing_checksum in existing_checksums
                ]:
                    merged_checksums.append(new_checksum)
            # Update checksums of updated files in merged checksums list
            for existing_checksum in existing_checksums:
                found = False
                for new_checksum in new_checksums:
                    if existing_checksum[1] == new_checksum[1]:
                        merged_checksums.append(new_checksum)
                        found = True
                        break
                if not found:
                    # Existing checksumed file has not been found in new
                    # checksum file, then keep existing checksum value.
                    merged_checksums.append(existing_checksum)
            with open(derivative_checksum_path, "w") as fh:
                for merged_checksum in merged_checksums:
                    fh.write(f"{merged_checksum[0]} *{merged_checksum[1]}\n")

        # Load keyring in agent
        self.instance.keyring.load_agent()

        # Sign checksum file. Note mkosi built-in signature feature (--sign) is
        # not used because, for security reasons, keyring is not available in
        # build container. The checksum file is signed the same way mkosi does
        # (as expected by systemd-importd) outside the build container.
        sig_path = derivative_checksum_path.with_suffix('.gpg')
        if sig_path.exists():
            logger.debug(
                "Removing existing checksums signature file %s", sig_path
            )
            sig_path.unlink()
        logger.info(
            "Signing checksum file %s with GPG", derivative_checksum_path
        )
        cmd = [
            'gpg',
            '--detach-sign',
            '--output',
            str(sig_path),
            '--default-key',
            self.instance.keyring.masterkey.userid,
            str(derivative_checksum_path),
        ]
        build.runcmd(cmd, env={'GNUPGHOME': str(self.instance.keyring.homedir)})

        built_files = []
        # The possible extensions for mkosi output files are .qcow2, .raw, .tar
        # and .cpio, possibly suffixed by compression algorithm (eg. .raw.xz).
        for extension in ['qcow2', 'raw', 'tar', 'cpio']:
            built_files.extend(
                [_path for _path in build.place.glob(f"*.{extension}*")]
            )
        logger.debug(
            "Found files: %s",
            ' '.join([built_file.name for built_file in built_files]),
        )

        for src in built_files:
            dst = derivative_path.joinpath(src.name)
            logger.debug("Copying file %s to %s", src, dst)
            shutil.copyfile(src, dst)

    def _artifacts_filter(self, distribution, derivative, name_filter=None):
        artifacts = []
        for _path in self.derivative_path(distribution, derivative).iterdir():
            if _path.name == RegistryOsi.CHECKSUMS_FILE:
                continue
            if _path.suffix == '.manifest':
                continue
            f_re = re.match(
                r'(?P<name>.+)_(?P<version>\d+)\.(?P<arch>.+)', _path.name
            )
            if not f_re:
                logger.warning(
                    "File %s does not match OSI artifact regular expression",
                    _path.name,
                )
                continue
            # skip if it does not match the filter
            if name_filter and f_re.group('name') != name_filter:
                continue
            artifacts.append(
                RegistryArtifact(
                    f_re.group('name'),
                    f_re.group('arch'),
                    f_re.group('version'),
                )
            )

        return artifacts

    def artifacts(self, distribution, derivative):
        """Returns the list of artifacts in OSI registry."""
        return self._artifacts_filter(distribution, derivative)

    def artifact_bins(self, distribution, derivative, src_artifact):
        """There is no notion of source/binary artifact with OSI format. This
        return the artifact whose name is the given source artifact."""
        return self._artifacts_filter(
            distribution, derivative, name_filter=src_artifact
        )

    def artifact_src(self, distribution, derivative, bin_artifact):
        """There is no notion of source/binary artifact with OSI format. This
        return the artifact whose name is the given binary artifact."""
        return self._artifacts_filter(
            distribution, derivative, name_filter=bin_artifact
        )[0]

    def changelog(self, distribution, derivative, architecture, artifact):
        """Return empty array as there is notion of changelog with OSI."""
        return []

    def delete_artifact(self, distribution, derivative, artifact):
        path = self.derivative_path(distribution, derivative).joinpath(
            f"{artifact.name}_{artifact.version}.{artifact.architecture}"
        )
        # delete the image if found
        if path.exists():
            logger.info("Deleting OSI file %s", path)
            path.unlink()
        else:
            logger.warning("Unable to find OSI file %s", path)
        # delete the manifest if found
        manifest = path.with_suffix('.manifest')
        if manifest.exists():
            logger.info("Deleting OSI manifest file %s", manifest)
            manifest.unlink()
        else:
            logger.warning("Unable to find OSI manifest file %s", manifest)

    @staticmethod
    def ensure_directory(path):
        """Create a directory with 0755 mode if it does not exist."""
        if not path.exists():
            logger.info("Creating directory %s", path)
            path.mkdir()
            path.chmod(0o755)
